# -*- coding: utf-8 -*-
"""content-based.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zwcMo9OmRd9eGy-WjE_49fV2aneKLeOO

Import necessary libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline

!pip install nltk

import nltk
nltk.download('stopwords')

"""Create dataframes"""

surveys = pd.read_csv('/content/dataset_kuesioner.xlsx - Sheet1.csv')

"""# Univariate Exploratory Data Analysis"""

surveys

surveys.info()

"""# Data Preparation

Check total data unique
"""

surveys.nunique()

"""Check duplicates"""

surveys.duplicated().sum()

print('Jumlah Surveys: ', len(surveys.judul.unique()))
print('Jumlah Row:', len(surveys))

surveys_duplicate = surveys[surveys.duplicated(['judul'], keep=False)]
surveys_duplicate = surveys_duplicate.sort_values('judul', ascending=True)
surveys_duplicate

surveys.drop_duplicates(subset=['judul'], keep='first', inplace=True)
surveys

"""Membuat dataframe baru dengan kolum yang hanya ingin digunakan"""

surveys = surveys[['judul', 'the_category']]
surveys

"""# Model Deployment

## Model Content Based Filtering
TF-IDF Vectorizer
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords

indonesian_stop_words = stopwords.words('indonesian')

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer(stop_words=indonesian_stop_words)

# Melakukan perhitungan idf pada data movies
tf.fit(surveys['the_category'])
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(surveys['the_category']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""### Cosine Similiraty"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=surveys['judul'],
                             columns=surveys['judul'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""Fungsi untuk rekomendasi survey"""

def SurveyRecommendations(movies_title, similarity_data=cosine_sim_df, 
                         items=surveys[['judul','the_category']], k=10):
  
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:, movies_title].to_numpy().argpartition(
        range(-1, -k, -1)
    )

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop survey_title agar nama movie yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(movies_title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

# Tes melihat genre dari sebuah movie
find_judul = surveys[surveys['judul'] == 'Penilaian Terhadap Peran Agama dalam Etika Pangan dan Kehidupan Berkelanjutan']
find_judul

survey_title = 'Penilaian Terhadap Peran Agama dalam Etika Pangan dan Kehidupan Berkelanjutan'
survey_recomend = SurveyRecommendations(survey_title)
survey_recomend